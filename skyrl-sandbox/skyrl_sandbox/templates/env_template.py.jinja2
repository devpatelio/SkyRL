"""{{ spec.env_name.capitalize() }} environment for SkyRL-Gym."""

import re
{% if spec.parsing.method == "json_path" or spec.reward.creation.method == "json_path_rule" %}
import json
from jsonpath_ng import parse as jsonpath_parse
{% endif %}
from typing import Any, Callable, Dict, List, Optional, Tuple
from skyrl_gym.envs.base_text_env import BaseTextEnv, BaseTextEnvStepOutput
from omegaconf import DictConfig
{% if spec.tools.enabled and spec.tools.get_enabled_tools() %}
{% for tool_type in spec.tools.get_enabled_tools() %}
{% if tool_type == "python" %}
from skyrl_gym.tools.python import PythonCodeExecutorToolGroup
{% elif tool_type == "sql" %}
from skyrl_gym.tools.sql import SQLCodeExecutorToolGroup
{% elif tool_type == "search" %}
from skyrl_gym.tools.search import SearchToolGroup
{% endif %}
{% endfor %}
{% endif %}


class {{ spec.env_name.capitalize() }}Env(BaseTextEnv):
    """
    {{ spec.description or "Environment generated by SkyRL Sandbox." }}

    Environment type: {{ spec.env_type }}
    {% if spec.env_type == "multi_turn" %}Max turns: {{ spec.max_turns }}{% endif %}
    Parsing method: {{ spec.parsing.method }}
    Reward creation: {{ spec.reward.creation.method }}
    Reward scheme: {{ spec.reward.scheme.scheme }}
    {% if spec.tools.enabled and spec.tools.get_enabled_tools() %}
    Tools enabled: {{ spec.tools.get_enabled_tools()|join(', ') }}
    {% endif %}
    """

    def __init__(
        self,
        env_config: DictConfig,
        extras: Dict[str, Any] = {},
        reward_overrides: Optional[Dict[str, Dict[str, Any]]] = None,
        llm_reward_fn: Optional[
            Callable[[str, Any, Dict[str, Any]], Dict[str, Any]]
        ] = None,
    ):
        super().__init__()
        
        # Extract ground_truth from extras (standard SkyRL-Gym pattern)
        assert "reward_spec" in extras, "reward_spec field is required"
        assert "ground_truth" in extras["reward_spec"], "ground_truth is required in reward_spec field"
        self.ground_truth = extras["reward_spec"]["ground_truth"]
        self.llm_reward_fn = llm_reward_fn

        base_creation = {{ spec.reward.creation.model_dump() }}
        base_scheme = {{ spec.reward.scheme.model_dump() }}

        reward_overrides = reward_overrides or {}
        self.reward_creation = reward_overrides.get("creation", base_creation)
        self.reward_scheme = reward_overrides.get("scheme", base_scheme)

        {% if spec.env_type == "multi_turn" %}
        self.max_turns = extras.get("max_turns", {{ spec.max_turns }})
        self.turns = 0
        {% endif %}

        {% if spec.tools.enabled and spec.tools.get_enabled_tools() %}
        # Initialize tools
        tools = []
        {% if "python" in spec.tools.get_enabled_tools() %}
        python_tools = PythonCodeExecutorToolGroup(
            timeout={{ spec.tools.python.timeout }},
            # Note: allowed_imports would be implemented in actual tool group
        )
        tools.append(python_tools)
        {% endif %}
        {% if "sql" in spec.tools.get_enabled_tools() %}
        sql_tools = SQLCodeExecutorToolGroup(
            db_file_path="{{ spec.tools.sql.db_file_path or '' }}",
            timeout={{ spec.tools.sql.timeout }},
            # Note: Additional SQL config would be implemented in actual tool group
        )
        tools.append(sql_tools)
        {% endif %}
        {% if "search" in spec.tools.get_enabled_tools() %}
        search_tools = SearchToolGroup(
            search_url="{{ spec.tools.search.search_url }}",
            max_results={{ spec.tools.search.max_results }},
            timeout={{ spec.tools.search.timeout }}
        )
        tools.append(search_tools)
        {% endif %}
        self.init_tool_groups(tools)
        {% endif %}

    def _parse_action(self, action: str) -> Any:
        """Extract answer from model output."""
        {% if spec.parsing.method == "regex" %}
        match = re.search(r"{{ spec.parsing.pattern }}", action)
        return match.group(1) if match else None
        {% elif spec.parsing.method == "json_path" %}
        try:
            data = json.loads(action)
            jsonpath_expr = jsonpath_parse("{{ spec.parsing.json_path }}")
            matches = jsonpath_expr.find(data)
            return matches[0].value if matches else None
        except (json.JSONDecodeError, Exception):
            return None
        {% endif %}

    def _evaluate_reward_signal(
        self,
        action: str,
        parsed_answer: Any,
    ) -> Tuple[bool, bool, Optional[float]]:
        """Return (is_correct, found_answer, raw_score)."""
        method = self.reward_creation.get("method", "parsed_answer_rule")
        found_answer = parsed_answer is not None
        raw_score: Optional[float] = None

        if method == "parsed_answer_rule":
            rule_type = self.reward_creation.get("rule_type", "exact_match")
            if rule_type == "exact_match":
                is_correct = (
                    parsed_answer is not None
                    and str(parsed_answer).strip() == str(self.ground_truth).strip()
                )
            elif rule_type == "regex_match":
                pattern = self.reward_creation.get("regex_pattern") or str(
                    self.ground_truth
                )
                is_correct = (
                    parsed_answer is not None
                    and re.match(str(pattern), str(parsed_answer)) is not None
                )
            elif rule_type == "numeric_tolerance":
                tolerance = float(self.reward_creation.get("numeric_tolerance") or 0.01)
                try:
                    if parsed_answer is not None:
                        answer_num = float(parsed_answer)
                        ground_truth_num = float(self.ground_truth)
                        is_correct = abs(answer_num - ground_truth_num) <= tolerance
                    else:
                        is_correct = False
                except (ValueError, TypeError):
                    is_correct = False
            else:
                is_correct = False
        elif method == "json_path_rule":
            is_correct = False
            found_answer = False
            json_path = self.reward_creation.get("json_path")
            if not json_path:
                return False, False, None
            try:
                data = json.loads(action)
                jsonpath_expr = jsonpath_parse(str(json_path))
                matches = jsonpath_expr.find(data)
                if matches:
                    value = matches[0].value
                    found_answer = True
                    success_values = self.reward_creation.get("json_success_values") or []
                    threshold = self.reward_creation.get("json_threshold")
                    if success_values:
                        is_correct = value in success_values
                    elif threshold is not None:
                        try:
                            raw_score = float(value)
                            is_correct = raw_score >= float(threshold)
                        except (TypeError, ValueError):
                            is_correct = False
            except Exception:
                is_correct = False
        elif method == "llm_verifier":
            found_answer = True
            if not self.llm_reward_fn:
                raise RuntimeError(
                    "llm_reward_fn must be provided when using llm_verifier rewards"
                )
            judge_result = self.llm_reward_fn(action, self.ground_truth, self.reward_creation)
            is_correct = bool(judge_result.get("is_correct"))
            judge_score = judge_result.get("score")
            raw_score = float(judge_score) if judge_score is not None else None
        else:
            is_correct = False

        return is_correct, found_answer, raw_score

    def _apply_scheme(
        self,
        is_correct: bool,
        found_answer: bool,
        raw_score: Optional[float],
    ) -> float:
        scheme = self.reward_scheme
        scheme_type = scheme.get("scheme", "binary")

        if scheme_type == "dense" and raw_score is not None:
            return float(raw_score)

        if is_correct:
            return float(scheme.get("correct_reward", 1.0))

        if not found_answer:
            return float(
                scheme.get("format_error_reward", scheme.get("incorrect_reward", 0.0))
            )

        if scheme.get("partial_reward") is not None and scheme_type in {"partial", "dense"}:
            return float(scheme["partial_reward"])

        return float(scheme.get("incorrect_reward", 0.0))

    def _calculate_reward(self, action: str, parsed_answer: Any) -> Dict[str, Any]:
        is_correct, found_answer, raw_score = self._evaluate_reward_signal(
            action, parsed_answer
        )
        reward = self._apply_scheme(is_correct, found_answer, raw_score)
        return {
            "reward": reward,
            "is_correct": is_correct,
            "found_answer": found_answer,
            "raw_score": raw_score,
        }

    {% if spec.tools.enabled and spec.tools.get_enabled_tools() %}
    def _parse_tool_call(self, action: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """Parse tool calls from action. Returns (tool_group, tool_name, tool_input)."""
        import re
        
        # Parse tool blocks like <tool><tool_name>input</tool_name></tool>
        tool_block_match = re.search(r"<tool>(.*?)</tool>", action, re.DOTALL)
        if not tool_block_match:
            return None, None, None
            
        tool_content = tool_block_match.group(1).strip()
        inner_tag_match = re.search(r"<(\w+)>(.*?)</\1>", tool_content, re.DOTALL)
        
        if not inner_tag_match:
            return None, None, None
            
        tool_name = inner_tag_match.group(1)
        tool_input = inner_tag_match.group(2).strip()
        
        # Map tool name to tool group
        tool_mapping = {
            {% if "python" in spec.tools.get_enabled_tools() %}
            "python": "PythonCodeExecutorToolGroup",
            {% endif %}
            {% if "sql" in spec.tools.get_enabled_tools() %}
            "sql": "SQLCodeExecutorToolGroup",
            {% endif %}
            {% if "search" in spec.tools.get_enabled_tools() %}
            "search": "SearchToolGroup",
            {% endif %}
        }
        
        tool_group = tool_mapping.get(tool_name)
        return tool_group, tool_name, tool_input
    {% endif %}

    def step(self, action: str) -> BaseTextEnvStepOutput:
        """Execute one step in the environment."""
        {% if spec.env_type == "multi_turn" %}
        self.turns += 1
        {% endif %}

        {% if spec.tools.enabled and spec.tools.get_enabled_tools() %}
        # Check if this is a tool call
        tool_group, tool_name, tool_input = self._parse_tool_call(action)
        if tool_group and tool_name and tool_input:
            try:
                tool_result = self._execute_tool(tool_group, tool_name, tool_input)
                # Return tool result and continue the conversation
                return BaseTextEnvStepOutput(
                    observations=[{"role": "user", "content": f"Tool result: {tool_result}"}],
                    reward=0.0,  # No reward for intermediate tool calls
                    done=False,
                    metadata={
                        "tool_used": tool_name,
                        "tool_result": tool_result,
                        {% if spec.env_type == "multi_turn" %}
                        "turns": self.turns,
                        {% endif %}
                    },
                )
            except Exception as e:
                # Return tool error and continue
                return BaseTextEnvStepOutput(
                    observations=[{"role": "user", "content": f"Tool error: {str(e)}"}],
                    reward=0.0,
                    done=False,
                    metadata={
                        "tool_used": tool_name,
                        "tool_error": str(e),
                        {% if spec.env_type == "multi_turn" %}
                        "turns": self.turns,
                        {% endif %}
                    },
                )
        {% endif %}

        answer = self._parse_action(action)
        reward_info = self._calculate_reward(action, answer)

        {% if spec.env_type == "single_turn" %}
        # Single-turn environment always ends after one step
        return BaseTextEnvStepOutput(
            observations=[],
            reward=reward_info["reward"],
            done=True,
            metadata={
                "parsed_answer": answer,
                "raw_score": reward_info["raw_score"],
                "is_correct": reward_info["is_correct"],
            },
        )
        {% elif spec.env_type == "multi_turn" %}
        # Determine if episode is done
        {% if spec.done_condition == "always_single_step" %}
        done = True
        {% elif spec.done_condition == "max_turns_only" %}
        done = self.turns >= self.max_turns
        {% elif spec.done_condition == "correct_or_max_turns" %}
        done = self.turns >= self.max_turns or reward_info["is_correct"]
        {% endif %}

        if done:
            return BaseTextEnvStepOutput(
                observations=[],
                reward=reward_info["reward"],
                done=True,
                metadata={
                    "parsed_answer": answer,
                    "raw_score": reward_info["raw_score"],
                    "is_correct": reward_info["is_correct"],
                    "turns": self.turns,
                },
            )

        # Provide feedback for another attempt
        if reward_info["found_answer"] and not reward_info["is_correct"]:
            feedback = """{{ spec.feedback.on_incorrect }}""".format(answer=answer)
        else:
            feedback = """{{ spec.feedback.on_format_error }}"""

        return BaseTextEnvStepOutput(
            observations=[{"role": "user", "content": feedback}],
            reward=0.0,
            done=False,
            metadata={
                "parsed_answer": answer,
                "raw_score": reward_info["raw_score"],
                "turns": self.turns,
            },
        )
        {% endif %}

